# Logistic-Regression-on-DonorsChoose-dataset
In the journey of exploring the flied of Data science and predictivemodeling, I explored this Very interesting algorithm Logistic Regression algorithm.I have tried to leverage the ability of the Classification algorithm whichcomes under Supervised learning of Section of predictive modeling. I used the Logistic Regression algorithm for theclassification of approval rate of the projects submitted by the teachers ofUnited states for students.The main business context of the Project was to reduce the manualevaluation of the projects that was done by volunteers as the process of evaluationcan take long time, which may also be biased on some factors and some irreducibleerrors could also be introduced into the processes. Some other import points are.·      How to scale current manual processes andresources to screen 500,000 projects so that they can be posted as quickly andas efficiently as possible·      How to increase the consistency of projectvetting across different volunteers to improve the experience for teachers·      How to focus volunteer time on the applicationsthat need the most assistance.The goal of the Project is to predict whether or not aDonorsChoose.org project proposal submitted by a teacher will be approved,using the text of project descriptions as well as additional metadata about theproject, teacher, and school. DonorsChoose.org can then use this information toidentify projects most likely to need further review before approvalThe steps followed for Data Preparation and PredictiveModeling is as follows:Note: Giving Unstructured data (Garbage in common terms) toa machine learning algorithm gives you random data (Garbage) again. All the code is written in a very clean and untestablemanner ignoring fancy methods where ever possible and reference for everything thatis used in coding is given above the code so that is it easy for everyone tounderstand the code and leverage the potential that AI has, because I believein growing together and helping others as this makes me a great team player . Italso increases the story telling ability and to represent data.For implementation of all the code I have used the SKlearn Library.  1.      Logistic Regression (either SGDClassifierwith log loss, or LogisticRegression) on these feature setsSet 1: categorical, numerical features+ project_title(BOW) + preprocessed_eassay (`BOW with bi-grams` with`min_df=10` and `max_features=5000`)Set 2: categorical, numericalfeatures + project_title(TFIDF)+ preprocessed_eassay (`TFIDF with bi-grams`with `min_df=10` and `max_features=5000`)Set 3: categorical, numericalfeatures + project_title(AVG W2V)+ preprocessed_eassay (AVG W2V)Set 4: categorical, numericalfeatures + project_title(TFIDF W2V)+ preprocessed_essay (TFIDF W2V) 2.      Hyper parameter tuning (find best hyperparameters corresponding the algorithm that you choose)1.      Find the best hyper parameter which will givethe maximum AUC value2.      Find the best hyper parameter using k-fold crossvalidation or simple cross validation data3.      Use gridsearch cv or random search cv or you canalso write your own for loops to do this task of hyperparameter tuning 3.      Representation of results1.      You need to plot the performance of model bothon train data and cross validation data for each hyper parameter, like shown inthe figure. 2.      Once after you found the best hyper parameter,you need to train your model with it, and find the AUC on test data and plotthe ROC curve on both train and test. 3.      Along with plotting ROC curve, you need to printthe confusion matrix with predicted and original labels of test data points.Please visualize your confusion matrices using seaborn heatmaps.  Task-2 Apply Logistic Regression on the belowfeature set Set 5 by finding the best hyper parameter as suggested in step 2and step 3.Consider these set of features Set 5 :school state : categorical dataclean categories : categorical dataclean subcategories : categorical dataproject_grade_category :categorical datateacher prefix : categorical dataquantity : numerical datateacher_number_of_previously_posted_projects : numerical dataprice : numerical datasentiment score's of each of the essay : numerical datanumber of words in the title : numerical datanumber of words in the combine essays : numerical dataAnd apply the Logistic regression on these features byfinding the best hyper paramter as suggested in step 2 and step 3 4 . ConclusionYou need to summarize the results at the end of thenotebook, summarize it in the table format. To print out a table please referto this pretty table library link.
